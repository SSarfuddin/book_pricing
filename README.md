# book_pricing
Machine Learning Predictive Pricing Model for Online Bookstore using NLP.
A combination of Natural Language Processing (NLP) and Machine Learning Model is proposed to build a robust recommendation engine and predictive book pricing model. By scraping and crawling data from amazon.com—a major online bookstore—relevant book details and current prices are collected. The NLP recommender analyses the semantic content of these details, while the Machine Learning Model predicts prices based on patterns detected in the data. This approach aims to enhance the consumer experience by providing personalized book recommendations and price predictions, thereby optimizing both customer satisfaction and sales strategies. The issue is pervasive across the World Wide Web, particularly in the realm of online bookstores like amazon.com. The process of sourcing data from amazon.com involves scraping book details and prices directly from the website’s search results pages.The Google Books API is particularly applied in the task to enrich the dataset. This dataset includes the books for which price information is available, ensuring that the data is both relevant and usable. Google Books API data is combined with the data scraped from amazon.com and the combination is achieved through concatenation of the respective DataFrames. Data wrangling included the removal of any duplicate entries that might have appeared due to overlap between the two data sources. The non-numeric elements of the target variable ‘price’ were removed to convert the price values into a numeric format suitable for analysis.The cleaning process involved stripping away any unnecessary characters from the price data and ensuring only valid numeric values were retained. Any entries that could not be properly converted into numeric format were flagged and treated as missing data. Additionally, the book details were standardized by converting them to lowercase. Normalization involved transforming the text data into a numerical format. Word2Vec is implemented to convert words into dense, continuous vectors that capture the context and meaning of each word based on its usage in the text. This approach allows for a richer representation of the book details than traditional methods like bag-of-words, which often lose contextual information. The normalization process also involved tokenization, where the text of the book details was split into individual words, or tokens. This step is crucial for word embeddings, as it breaks 
down the text into manageable units that can be further processed. The tokens were then used to train a Word2Vec model, which learned to represent each word as a vector in a multidimensional space. The trained Word2Vec model was then applied to the book details to generate a numerical vector for each book, representing the combined meaning of its title, author, description, and other information. Feature extraction focused on generating meaningful numerical representations from the text data of book details. The primary feature extracted is the Word2Vec-generated embedding for each book. 

A stacking regressor model is implemented to predict book prices based on book details embeddings, which serve as features derived from the text and metadata. The stacking regressor was constructed with three base models: Ridge Regression, Random Forest Regressor, and XGBoost Regressor. Each model is carefully tuned with specific hyperparameters to optimize its performance. These diverse models are selected to leverage their unique strengths: Ridge for its simplicity and effectiveness in linear problems, Random Forest for its robustness against overfitting and ability to handle non-linear relationships, and XGBoost for its high predictive power and 
handling of complex interactions. The meta-learner, or final estimator, in the stacking model is another Ridge regression model, with a lower regularization parameter (alpha=0.3), chosen for its ability to combine the outputs of the base models effectively without introducing too much bias.

The Machine Learning Model predictive approach leverages a combination of text embeddings derived from book details and encoded categorical features to make book price predictions. After preparing the features, the dataset is split into training and testing sets. The training set is used to fit the RandomForestRegressor model, which is a robust ensemble learning method that builds multiple decision trees and combines their outputs to make more accurate and stable predictions. The process involves converting the book details into numerical representations that can be processed by the ML model. This is done using a Word2Vec model, which generates embeddings for the book details. These embeddings capture the semantic meaning of the text by converting the words into vectors of numbers, where similar words or phrases have vectors that are close together in the high-dimensional 
space. To enhance the feature set, categorical data representing book details are encoded into numerical labels using a LabelEncoder.  This encoding process transforms the categorical information into a format that the model can process alongside the word embeddings. In the prediction process the new book's detail is tokenized into individual words and filtering these tokens to retain only those that are present in the Word2Vec model's 
vocabulary. The Word2Vec model is then used to generate an embedding for the new book information.  The final feature vector for the new book is constructed by appending the label-encoded value to the title embedding. The combined feature set, consisting of both the word embeddings and the encoded categorical data, creates a rich feature set that the model can use to learn patterns related to book prices.  The ML Model can also predict the price of a new book that is not part of the original dataset. 
